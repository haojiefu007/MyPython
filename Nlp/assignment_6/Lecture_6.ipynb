{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is a short introduction to keras and TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "/\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x  #gpu\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic of TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run simple matrix calculations using tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "x matmul x = [[4.]]\n"
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "\n",
    "m = tf.matmul(x,x)\n",
    "print(\"x matmul x = {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tf.Tensor(\n[[1 2]\n [3 4]], shape=(2, 2), dtype=int32)\n"
    }
   ],
   "source": [
    "#创建向量\n",
    "a = tf.constant([[1,2],\n",
    "                 [3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tf.Tensor(\n[[2 3]\n [4 5]], shape=(2, 2), dtype=int32)\n"
    }
   ],
   "source": [
    "#Broadcasting \n",
    "b = tf.add(a,1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tf.Tensor(\n[[ 2  6]\n [12 20]], shape=(2, 2), dtype=int32)\n"
    }
   ],
   "source": [
    "#element-wise multiplication\n",
    "print(a*b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tf.Tensor(\n[[10 13]\n [22 29]], shape=(2, 2), dtype=int32)\n"
    }
   ],
   "source": [
    "#矩阵乘法\n",
    "print(tf.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager execution works perfectly with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 2  6]\n [12 20]]\ntf.Tensor(\n[[ 2  6]\n [12 20]], shape=(2, 2), dtype=int32)\n"
    }
   ],
   "source": [
    "c = np.multiply(a,b)\n",
    "print(c)\n",
    "print(tf.multiply(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1 2]\n [3 4]]\n"
    }
   ],
   "source": [
    "#Transfer a tensor to numpy array\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks. During eager execution, use tf.GradientTape to trace operations for computing gradients later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
    }
   ],
   "source": [
    "#参数初始化\n",
    "w = tf.Variable([[1.0]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w\n",
    "#loss对于w的导数\n",
    "grad = tape.gradient(loss,w)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist：一个收录了许多 28 x 28 像素手写数字图片（以灰度值矩阵存储）及其对应的数字的数据集\n",
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:10000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "x_test = x_test[:1000,:,:]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train[...,tf.newaxis]/255, tf.float32),\n",
    "x_test = tf.cast(x_test[...,tf.newaxis]/255, tf.float32),\n",
    "\n",
    "#y_train = y_train.astype('float32')\n",
    "#y_test = y_test.astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model using Sequential\n",
    "\n",
    "mnist_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,[3,3],activation='relu',\n",
    "                          input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Conv2D(64,[3,3],activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 12, 12, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 9216)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               1179776   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 1,199,882\nTrainable params: 1,199,882\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model using Model\n",
    "inputs = tf.keras.Input(shape=(None,None,1),name=\"digits\")\n",
    "conv_1 = tf.keras.layers.Conv2D(16,[3,3],activation=\"relu\")(inputs)\n",
    "conv_2 = tf.keras.layers.Conv2D(16,[3,3],activation=\"relu\")(conv_1)\n",
    "ave_pool = tf.keras.layers.GlobalAveragePooling2D()(conv_2)\n",
    "outputs = tf.keras.layers.Dense(10)(ave_pool)\n",
    "mnist_model_2 = tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndigits (InputLayer)          [(None, None, None, 1)]   0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, None, None, 16)    160       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, None, None, 16)    2320      \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 16)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                170       \n=================================================================\nTotal params: 2,650\nTrainable params: 2,650\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "mnist_model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two training methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use keras fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "#validation_split=0.1,shuffle=True,\n",
    "loss = tf.keras.losses.categorical_crossentropy,\n",
    "metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model_2.compile(loss = tf.keras.losses.categorical_crossentropy,\n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 9000 samples, validate on 1000 samples\nEpoch 1/3\n9000/9000 [==============================] - 11s 1ms/sample - loss: 2.3004 - accuracy: 0.1096 - val_loss: 2.2837 - val_accuracy: 0.1050\nEpoch 2/3\n9000/9000 [==============================] - 10s 1ms/sample - loss: 2.2836 - accuracy: 0.1263 - val_loss: 2.2651 - val_accuracy: 0.1210\nEpoch 3/3\n9000/9000 [==============================] - 10s 1ms/sample - loss: 2.2678 - accuracy: 0.1571 - val_loss: 2.2455 - val_accuracy: 0.1870\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1f6ad67db08>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.fit(x_train,y_train,batch_size=128,epochs=3,validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1000/1000 [==============================] - 0s 396us/sample - loss: 2.2619 - accuracy: 0.1270\n"
    },
    {
     "data": {
      "text/plain": "[2.2619345397949218, 0.127]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10000, 28, 28, 1), dtype=float32, numpy=\narray([[[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       ...,\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]]], dtype=float32)>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1000, 28, 28, 1), dtype=float32, numpy=\narray([[[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       ...,\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]]], dtype=float32)>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.10254677, 0.10227727, 0.1021947 , ..., 0.10914966, 0.09872025,\n        0.0981361 ],\n       [0.1099027 , 0.09906453, 0.09253234, ..., 0.09465276, 0.08678333,\n        0.08612898],\n       [0.09858585, 0.1030165 , 0.09509578, ..., 0.1038053 , 0.09656586,\n        0.10024641],\n       ...,\n       [0.12909204, 0.09256257, 0.09179167, ..., 0.10134144, 0.08005463,\n        0.08427463],\n       [0.1126183 , 0.09683283, 0.09378768, ..., 0.10304978, 0.09000884,\n        0.09481616],\n       [0.10139098, 0.09928598, 0.10330585, ..., 0.10232206, 0.09451264,\n        0.09735424]], dtype=float32)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.predict(x_test[0])\n",
    "#mnist_model.predict(x_test[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF 2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[:10000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "x_test = x_test[:1000,:,:]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "(tf.cast(x_train[...,tf.newaxis]/255, tf.float32),\n",
    " tf.cast(y_train,tf.int64)))\n",
    "dataset = dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 0 finishted\nEpoch 1 finishted\nEpoch 2 finishted\nEpoch 3 finishted\nEpoch 4 finishted\n"
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    \n",
    "    for (batch, (images,labels)) in enumerate (dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            logits = mnist_model(images,training=True)\n",
    "            loss_value = loss(labels,logits)\n",
    "            \n",
    "        grads = tape.gradient(loss_value,mnist_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,mnist_model.trainable_variables))\n",
    "        \n",
    "    print(\"Epoch {} finishted\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}